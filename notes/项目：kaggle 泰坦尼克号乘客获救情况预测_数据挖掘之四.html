<!DOCTYPE html>
<!-- saved from url=(0099)file:///private/var/folders/jq/l66hzx9956qbmxs_990g1djh0000gn/T/mume2020317-90899-5f5sl6.kj8gk.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>项目：kaggle 泰坦尼克号乘客获救情况预测_数据挖掘之四</title>
      
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="./项目：kaggle 泰坦尼克号乘客获救情况预测_数据挖掘之四_files/katex.min.css">
      
      

      
      
      
      
      
      
      

      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h2 class="mume-header" id="%E9%A1%B9%E7%9B%AEkaggle-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E8%8E%B7%E6%95%91%E6%83%85%E5%86%B5%E9%A2%84%E6%B5%8B">项目：kaggle 泰坦尼克号乘客获救情况预测</h2>

<h3 class="mume-header" id="%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B9%8B%E5%9B%9B%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B">数据挖掘之四：模型建立</h3>

<hr>
<p>接下来需要将特征变量的值取出来转换成 numpy 格式，然后使用 scikit-learn 中的 LogisticRegression 来建立模型。</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># 建立模型</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> linear_model

<span class="token comment"># 将原来数据中的 PassengerId 列也 drop() 掉，并转换为数组格式</span>
data_train_fix <span class="token operator">=</span> df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values

<span class="token comment"># y 即Survival结果</span>
y <span class="token operator">=</span> data_train_fix<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
<span class="token comment"># X 即特征属性值</span>
X <span class="token operator">=</span> data_train_fix<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token comment"># fit到RandomForestRegressor之中；C为正则化系数；penalty参数可选择的值为"l1"和"l2".分别对应L1的正则化和L2的正则化，默认是L2的正则化；tol迭代终止判据的误差范围</span>
clf <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>LogisticRegression<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> penalty<span class="token operator">=</span><span class="token string">'l1'</span><span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
</pre><p>此时就可以得到一个模型了。</p>
<p>下面将 test 数据也导进来并做相同的处理。</p>
<p>在开始进行对 test 数据进行类似的处理之前，我们还是先看一下 test 数据的大概情况。如下：</p>
<pre data-role="codeBlock" data-info="python" class="language-python">data_test_origin <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'data/test.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">)</span>
data_test <span class="token operator">=</span> data_test_origin<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data_test<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><p>输出结果如下：</p>
<pre data-role="codeBlock" data-info="shell" class="language-shell"><span class="token operator">&lt;</span>class <span class="token string">'pandas.core.frame.DataFrame'</span><span class="token operator">&gt;</span>
RangeIndex: 418 entries, 0 to 417
Data columns <span class="token punctuation">(</span>total 11 columns<span class="token punctuation">)</span>:
PassengerId    418 non-null int64
Pclass         418 non-null int64
Name           418 non-null object
Sex            418 non-null object
Age            332 non-null float64
SibSp          418 non-null int64
Parch          418 non-null int64
Ticket         418 non-null object
Fare           417 non-null float64
Cabin          91 non-null object
Embarked       418 non-null object
dtypes: float64<span class="token punctuation">(</span>2<span class="token punctuation">)</span>, int64<span class="token punctuation">(</span>4<span class="token punctuation">)</span>, object<span class="token punctuation">(</span>5<span class="token punctuation">)</span>
memory usage: 36.0+ KB
None
</pre><p>从中可以看出，与 train 数据不同的是，Fare 列数据中有一项数据是空值。</p>
<p>如果此时直接将 test 数据运用在之前新建的 <code>set_missing_age()</code> 函数中，就会因为输入数据中有空值而导致随机森林预测年龄失败。</p>
<p>因为只有一个空值项，初步可能会想到直接将该数据丢弃就好，但是由于后面要提交的是所有的测试数据，所以不采取这种方法，而是用 Fare 这一列的平均值来填充该缺失值。</p>
<hr>
<p><strong>除此之外，由于在进行 test 数据进行处理的时候觉得之前的代码有点乱，所以对之前的代码进行了部分的重写。下面的代码是重写后的代码。</strong></p>
<hr>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># test 数据处理</span>
data_test_origin <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'data/test.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">)</span>
data_test <span class="token operator">=</span> data_test_origin<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># print(data_test.info())  # 发现 Fare 中有空值</span>
<span class="token comment"># print(data_test.loc[:][data_test['Fare'].isnull()])  # 可以查看下该行</span>

<span class="token comment"># 这里还是不把 Fare 为空的情况直接删除了，不然后面提交数据的时候会比较麻烦</span>
<span class="token comment"># data_test.drop([152], inplace=True)  # 删除 Fare 为空值的行</span>
<span class="token comment"># # print(data_test.info())</span>

<span class="token comment"># 直接给该 Fare 赋 Fare 这一列的平均值</span>
fare_mean <span class="token operator">=</span> data_test<span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># print(fare_mean)</span>
data_test<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">152</span><span class="token punctuation">,</span> <span class="token string">'Fare'</span><span class="token punctuation">]</span> <span class="token operator">=</span> fare_mean

X_data_test_age_predict <span class="token operator">=</span> data_test<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">,</span> <span class="token string">'Parch'</span><span class="token punctuation">,</span> <span class="token string">'SibSp'</span><span class="token punctuation">,</span>
                                     <span class="token string">'Pclass'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span>data_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
data_test_age_predicted_value <span class="token operator">=</span> age_predict_rfr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>
    X_data_test_age_predict<span class="token punctuation">)</span>
data_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>data_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> data_test_age_predicted_value
<span class="token keyword">print</span><span class="token punctuation">(</span>set_Cabin_type<span class="token punctuation">(</span>data_test<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 因子化处理</span>
dummies_Cabin <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_test<span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Cabin'</span><span class="token punctuation">)</span>
dummies_Sex <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_test<span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Sex'</span><span class="token punctuation">)</span>
dummies_Embarked <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_test<span class="token punctuation">[</span><span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Embarked'</span><span class="token punctuation">)</span>
dummies_Pclass <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_test<span class="token punctuation">[</span><span class="token string">'Pclass'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Pclass'</span><span class="token punctuation">)</span>

<span class="token comment"># 拼接</span>
df_test <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>data_test<span class="token punctuation">,</span> dummies_Cabin<span class="token punctuation">,</span> dummies_Embarked<span class="token punctuation">,</span> dummies_Sex<span class="token punctuation">,</span> dummies_Pclass<span class="token punctuation">]</span><span class="token punctuation">,</span>
    axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 丢弃</span>
df_test<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Pclass'</span><span class="token punctuation">,</span> <span class="token string">'Name'</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">,</span> <span class="token string">'Ticket'</span><span class="token punctuation">,</span> <span class="token string">'Cabin'</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
             axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
             inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 归一化</span>
scaler_age <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>df_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> scaler_age
scaler_fare <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>df_test<span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df_test<span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">]</span> <span class="token operator">=</span> scaler_fare
data_test_fix <span class="token operator">=</span> df_test<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values
</pre><p>得到处理过后的 test 数据之后，开始对其进行预测：</p>
<pre data-role="codeBlock" data-info="python" class="language-python">survived_predict <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data_test_fix<span class="token punctuation">)</span>
</pre><p>预测完成后将数据进行简单汇总并导出：</p>
<pre data-role="codeBlock" data-info="python" class="language-python">result <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">'PassengerId'</span><span class="token punctuation">:</span> data_test<span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'Survived'</span><span class="token punctuation">:</span> survived_predict<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
result<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'logistic_regression_predictions.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</pre><p>至此就用一个初步的模型对数据进行了预测。接下来就是对优化工作了。</p>
<p>至此，完整代码如下：</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestRegressor
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing

data_train <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'data/train.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">)</span>


<span class="token comment"># 使用RandomForestClassifier填补缺失的年龄属性</span>
<span class="token keyword">def</span> <span class="token function">set_missing_age</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 把已有的数值型特征取出来传入Random Forest Regressor中</span>
    age_df <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">,</span> <span class="token string">'Fare'</span><span class="token punctuation">,</span> <span class="token string">'Parch'</span><span class="token punctuation">,</span> <span class="token string">'SibSp'</span><span class="token punctuation">,</span> <span class="token string">'Pclass'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token comment"># 将乘客分成已知年龄和未知年龄两部分</span>
    known_age <span class="token operator">=</span> age_df<span class="token punctuation">[</span>age_df<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>notnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values
    unknown_age <span class="token operator">=</span> age_df<span class="token punctuation">[</span>age_df<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values

    y <span class="token operator">=</span> known_age<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
    X <span class="token operator">=</span> known_age<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

    rfr <span class="token operator">=</span> RandomForestRegressor<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> n_estimators<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">)</span>
    rfr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

    predictedAges <span class="token operator">=</span> rfr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>unknown_age<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    age_predict <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> predictedAges

    <span class="token keyword">return</span> df<span class="token punctuation">,</span> rfr


set_missing_age<span class="token punctuation">(</span>data_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data_train<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">set_Cabin_type</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
    df<span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>notnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'yes'</span>  <span class="token comment"># 注意这两个顺序不能调换</span>
    df<span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'no'</span>
    <span class="token keyword">return</span> df


set_Cabin_type<span class="token punctuation">(</span>data_train<span class="token punctuation">)</span>

<span class="token comment"># 因子化处理</span>
dummies_Cabin <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_train<span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Cabin'</span><span class="token punctuation">)</span>
dummies_Sex <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_train<span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Sex'</span><span class="token punctuation">)</span>
dummies_Embarked <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_train<span class="token punctuation">[</span><span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Embarked'</span><span class="token punctuation">)</span>
dummies_Pclass <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_train<span class="token punctuation">[</span><span class="token string">'Pclass'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Pclass'</span><span class="token punctuation">)</span>

<span class="token comment"># 将因子化后得到的 Dataframe 与原始的 Dataframe 进行拼接</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>data_train<span class="token punctuation">,</span> dummies_Cabin<span class="token punctuation">,</span> dummies_Embarked<span class="token punctuation">,</span> dummies_Sex<span class="token punctuation">,</span> dummies_Pclass<span class="token punctuation">]</span><span class="token punctuation">,</span>
    axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># 将不需要的列“丢弃”掉；</span>
df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Pclass'</span><span class="token punctuation">,</span> <span class="token string">'Name'</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">,</span> <span class="token string">'Ticket'</span><span class="token punctuation">,</span> <span class="token string">'Cabin'</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment"># print(df)</span>

<span class="token comment"># 归一化处理</span>
scaler_age <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> scaler_age
scaler_fare <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">]</span> <span class="token operator">=</span> scaler_fare

<span class="token comment"># 建立模型</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> linear_model

<span class="token comment"># 将原来数据中的 PassengerId 列也 drop() 掉，并转换为数组格式</span>
data_train_fix <span class="token operator">=</span> df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values

<span class="token comment"># y 即Survival结果</span>
y <span class="token operator">=</span> data_train_fix<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
<span class="token comment"># X 即特征属性值</span>
X <span class="token operator">=</span> data_train_fix<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token comment"># fit到RandomForestRegressor之中；C为正则化系数；penalty参数可选择的值为"l1"和"l2".分别对应L1的正则化和L2的正则化，默认是L2的正则化；tol迭代终止判据的误差范围</span>
clf <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>LogisticRegression<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> penalty<span class="token operator">=</span><span class="token string">'l1'</span><span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token comment"># test 数据处理</span>
data_test_origin <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'data/test.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'python'</span><span class="token punctuation">)</span>
data_test <span class="token operator">=</span> data_test_origin<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># print(data_test.info())  # 发现 Fare 中有空值</span>
<span class="token comment"># print(data_test.loc[:][data_test['Fare'].isnull()])  # 可以查看下该行</span>

<span class="token comment"># 这里还是不把 Fare 为空的情况直接删除了，不然后面提交数据的时候会比较麻烦</span>
<span class="token comment"># data_test.drop([152], inplace=True)  # 删除 Fare 为空值的行</span>
<span class="token comment"># # print(data_test.info())</span>

<span class="token comment"># 直接给该 Fare 赋 Fare 这一列的平均值</span>
fare_mean <span class="token operator">=</span> data_test<span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># print(fare_mean)</span>
data_test<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">152</span><span class="token punctuation">,</span> <span class="token string">'Fare'</span><span class="token punctuation">]</span> <span class="token operator">=</span> fare_mean

X_data_test_age_predict <span class="token operator">=</span> data_test<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">,</span> <span class="token string">'Parch'</span><span class="token punctuation">,</span> <span class="token string">'SibSp'</span><span class="token punctuation">,</span>
                                     <span class="token string">'Pclass'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span>data_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
data_test_age_predicted_value <span class="token operator">=</span> age_predict_rfr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>
    X_data_test_age_predict<span class="token punctuation">)</span>
data_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>data_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> data_test_age_predicted_value
<span class="token comment"># print(set_Cabin_type(data_test))</span>

<span class="token comment"># 因子化处理</span>
dummies_Cabin <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_test<span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Cabin'</span><span class="token punctuation">)</span>
dummies_Sex <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_test<span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Sex'</span><span class="token punctuation">)</span>
dummies_Embarked <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_test<span class="token punctuation">[</span><span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Embarked'</span><span class="token punctuation">)</span>
dummies_Pclass <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_test<span class="token punctuation">[</span><span class="token string">'Pclass'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'Pclass'</span><span class="token punctuation">)</span>

<span class="token comment"># 拼接</span>
df_test <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>data_test<span class="token punctuation">,</span> dummies_Cabin<span class="token punctuation">,</span> dummies_Embarked<span class="token punctuation">,</span> dummies_Sex<span class="token punctuation">,</span> dummies_Pclass<span class="token punctuation">]</span><span class="token punctuation">,</span>
    axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 丢弃</span>
df_test<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Pclass'</span><span class="token punctuation">,</span> <span class="token string">'Name'</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">,</span> <span class="token string">'Ticket'</span><span class="token punctuation">,</span> <span class="token string">'Cabin'</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
             axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
             inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 归一化</span>

scaler_age <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>df_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df_test<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span> <span class="token operator">=</span> scaler_age
scaler_fare <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>df_test<span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df_test<span class="token punctuation">[</span><span class="token string">'Fare'</span><span class="token punctuation">]</span> <span class="token operator">=</span> scaler_fare

data_test_fix <span class="token operator">=</span> df_test<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values
survived_predict <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data_test_fix<span class="token punctuation">)</span>

result <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">'PassengerId'</span><span class="token punctuation">:</span> data_test<span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'Survived'</span><span class="token punctuation">:</span> survived_predict<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
result<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'logistic_regression_predictions.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</pre><p>将上述结果稍作整理后上传至 kaggle，可以得到 score = 0.76555。</p>
<hr>

      </div>
      
      
    
    
    
    
    
    
    
    
  </body></html>